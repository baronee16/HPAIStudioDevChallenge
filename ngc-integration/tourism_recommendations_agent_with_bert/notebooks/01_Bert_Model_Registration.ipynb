{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6b00c4-cd29-4b59-bed6-a81f08ccc49d",
   "metadata": {},
   "source": [
    "# Bert Model Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f5d4c-0e1c-47ce-82d0-c6f6b1a5bf8b",
   "metadata": {},
   "source": [
    "This Jupyter Notebook implements a BERT-based similarity model using MLflow for tracking, managing, and deploying the model. It loads a pre-trained BERT model, computes sentence embeddings, and retrieves the most similar sentences from a stored corpus based on cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648f1d2-42ee-40a5-9ded-c9db243fe4d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Notebook Overview\n",
    "- Import dependencies\n",
    "- Configure Logging and Define Constants and Paths\n",
    "- Downloading the Bert Large Uncased Model\n",
    "- Defining the BERT Tourism Model Class\n",
    "- Logging Model to MLflow\n",
    "- Fetching the Latest Model Version from MLflow\n",
    "- Loading the Model and Running Inference\n",
    "- Displaying Results for the Input Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c2be1-7e41-4318-b54b-74c0860ac597",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b853f387-e023-46f8-bb01-a7db1049e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import logging\n",
    "\n",
    "# Third-Party Libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# MLflow for Experiment Tracking and Model Management\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec, TensorSpec, ParamSchema, ParamSpec\n",
    "\n",
    "# Transformers and NLP Libraries\n",
    "from transformers import AutoTokenizer\n",
    "from nemo.collections.nlp.models.language_modeling import BERTLMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b91d09-b0de-4beb-bf3a-5da46b0fc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Suppress Verbose Logs ------------------------\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Hugging Face Transformers logs\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "# NVIDIA NeMo logs\n",
    "logging.getLogger(\"nemo_logger\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a184b-c233-4f16-9470-ae626e929746",
   "metadata": {},
   "source": [
    "## Configure Logging and Define Constants and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e15023-c68e-4927-a65a-1c76bceb0d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger\n",
    "logger = logging.getLogger(\"notebook_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", \n",
    "                              datefmt=\"%Y-%m-%d %H:%M:%S\") \n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d83959-2359-4078-83f8-df8298b5a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH = \"../data/raw/corpus.csv\"\n",
    "EMBEDDINGS_PATH = \"../data/processed/embeddings.csv\"\n",
    "TOKENIZER_DIR = \"../artifacts/tokenizer\"\n",
    "BERT_MODEL_NAME = \"bert-large-uncased\"\n",
    "BERT_MODEL_ONLINE_PATH = \"/root/.cache/torch/NeMo/NeMo_1.22.0/bertlargeuncased/ca4ebba9f05a8ffb79845249ca046983/bertlargeuncased.nemo\"\n",
    "BERT_MODEL_DATAFABRIC_PATH = \"/home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo\"\n",
    "DEMO_PATH = \"../demo\"\n",
    "EXPERIMENT_NAME = \"BERT_Tourism_Experiment\"\n",
    "RUN_NAME = \"BERT_Tourism_Run\"\n",
    "MODEL_NAME = \"BERT_Tourism_Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a29711-69f5-41d6-bde8-ca259cea0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 02:27:49 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "logger.info('Notebook execution started.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba22c2a-f741-4a60-90e6-07a0fc5a97a6",
   "metadata": {},
   "source": [
    "# Downloading the Bert Large Uncased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2190db-3753-4eae-9520-4eed793e6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have added the 'bertlargeuncased' model from the NVIDIA NGC model catalog.\n",
    "# If unavailable, uncomment the following line and use the alternative method below to download the BERT model online.\n",
    "# bert_model = BERTLMModel.from_pretrained(model_name=\"bertlargeuncased\", strict=False).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85769bcb-33a8-4c27-8ede-f0f80d6d8785",
   "metadata": {},
   "source": [
    "# Defining the BERT Tourism Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d71dcb-0ac2-4e8a-b03c-131600a9be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTTourismModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        \"\"\"\n",
    "        Load precomputed embeddings, corpus, and the pre-trained BERT model.\n",
    "        \"\"\"\n",
    "        # Load precomputed embeddings and corpus data\n",
    "        self.embeddings_df = pd.read_csv(context.artifacts['embeddings_path'])\n",
    "        self.corpus_df = pd.read_csv(context.artifacts['corpus_path'])\n",
    "        \n",
    "        # Load tokenizer for BERT\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(context.artifacts[\"tokenizer_dir\"])\n",
    "        \n",
    "        # Set device to GPU if available, otherwise use CPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load pre-trained BERT model\n",
    "        self.bert_model = BERTLMModel.restore_from(context.artifacts['bert_model_path'], strict=False).to(self.device)\n",
    "    \n",
    "    def generate_query_embedding(self, query):\n",
    "        \"\"\"\n",
    "        Generate BERT embeddings for the input query.\n",
    "        \"\"\"\n",
    "        self.bert_model.eval()  # Set model to evaluation mode\n",
    "        \n",
    "        # Tokenize the input query and move tensors to the selected device\n",
    "        encoded_input = self.tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "        \n",
    "        # Get the model's output embedding\n",
    "        with torch.no_grad():\n",
    "            output = self.bert_model.bert_model(**encoded_input)\n",
    "        \n",
    "        # Return the [CLS] token embedding as a NumPy array\n",
    "        return output[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    def predict(self, context, model_input, params):\n",
    "        \"\"\"\n",
    "        Compute similarity between query and precomputed embeddings,\n",
    "        then return the top 5 most similar results.\n",
    "        \"\"\"\n",
    "        # Extract the query string from model input\n",
    "        query = model_input[\"query\"][0]\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.generate_query_embedding(query)\n",
    "        \n",
    "        # Compute cosine similarity between query and precomputed embeddings\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings_df.values)\n",
    "        \n",
    "        # Get indices of top 5 most similar results\n",
    "        top_indices = np.argsort(similarities[0])[::-1][:5]\n",
    "        \n",
    "        # Retrieve corresponding results from the corpus\n",
    "        results = self.corpus_df.iloc[top_indices].copy()\n",
    "        results.loc[:, 'Similarity'] = similarities[0][top_indices]\n",
    "        \n",
    "        # Return results as a dictionary\n",
    "        return results.to_dict(orient=\"records\")\n",
    "    \n",
    "    @classmethod\n",
    "    def log_model(cls, model_name):\n",
    "        \"\"\"\n",
    "        Logs the model to MLflow with appropriate artifacts and schema.\n",
    "        \"\"\"\n",
    "        # Define input and output schema\n",
    "        input_schema = Schema([ColSpec(\"string\", \"query\")])\n",
    "        output_schema = Schema([\n",
    "            TensorSpec(np.dtype(\"object\"), (-1,), \"List of Pledges and Similarities\")\n",
    "        ])\n",
    "        params_schema = ParamSchema([ParamSpec(\"show_score\", \"boolean\", False)])\n",
    "        \n",
    "        # Define model signature\n",
    "        signature = ModelSignature(inputs=input_schema, outputs=output_schema, params=params_schema)\n",
    "        \n",
    "        # Log the model in MLflow\n",
    "        mlflow.pyfunc.log_model(\n",
    "            model_name,\n",
    "            python_model=cls(),\n",
    "            artifacts={\n",
    "                \"corpus_path\": CORPUS_PATH,\n",
    "                \"embeddings_path\": EMBEDDINGS_PATH, \n",
    "                \"tokenizer_dir\": TOKENIZER_DIR, \n",
    "                # If you are using the downloaded bert model then uncomment the line below and comment the other bert model line that uses nemo model from datafabric\n",
    "                #\"bert_model_path\": BERT_MODEL_ONLINE_PATH,            \n",
    "                \"bert_model_path\": BERT_MODEL_DATAFABRIC_PATH,\n",
    "                \"demo\": DEMO_PATH,\n",
    "            },\n",
    "            signature=signature\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0913e-b149-4ebf-9a6a-b3a2bb5676a0",
   "metadata": {},
   "source": [
    " # Logging Model to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6bbc01e-d831-4aea-bd80-fc20ff5576f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 02:27:49 - INFO - Starting the experiment: BERT_Tourism_Experiment\n",
      "2025/04/07 02:27:49 INFO mlflow.tracking.fluent: Experiment with name 'BERT_Tourism_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c072f6183944624a7f81e63568e84e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dbc901b7dc4d64a081714ffe714983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23330d740003451fada27441eea1f440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60c9384c77b4a23939543f514989d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8766b06ede024ec1a00e3e28aeeb0597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/07 02:28:30 WARNING mlflow.utils.requirements_utils: Found transformer-engine version (0.13.0+8eae4ce) contains a local version label (+8eae4ce). MLflow logged a pip requirement for this package as 'transformer-engine==0.13.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Successfully registered model 'BERT_Tourism_Model'.\n",
      "Created version '1' of model 'BERT_Tourism_Model'.\n",
      "2025-04-07 02:29:04 - INFO - Registered the model: BERT_Tourism_Model\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Starting the experiment: {EXPERIMENT_NAME}')\n",
    "\n",
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    # Print the artifact URI for reference\n",
    "    logging.info(f\"Run's Artifact URI: {run.info.artifact_uri}\")\n",
    "    \n",
    "    # Log the BERT similarity model to MLflow\n",
    "    BERTTourismModel.log_model(model_name=MODEL_NAME)\n",
    "\n",
    "    # Register the logged model in MLflow Model Registry\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run.info.run_id}/{MODEL_NAME}\", \n",
    "        name=MODEL_NAME\n",
    "    )\n",
    "\n",
    "logger.info(f'Registered the model: {MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686985b-88a6-4f23-9833-a8a13f4db282",
   "metadata": {},
   "source": [
    "# Fetching the Latest Model Version from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49dc9da2-9f32-45b8-82a7-33c2c6b1427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Model Version: 1\n",
      "Model Signature: inputs: \n",
      "  ['query': string (required)]\n",
      "outputs: \n",
      "  ['List of Pledges and Similarities': Tensor('object', (-1,))]\n",
      "params: \n",
      "  ['show_score': boolean (default: False)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve the latest version of the \"BERT_Tourism_Model\" model (not yet in a specific stage)\n",
    "model_metadata = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])\n",
    "latest_model_version = model_metadata[0].version  # Extract the latest model version\n",
    "\n",
    "# Fetch model information, including its signature\n",
    "model_info = mlflow.models.get_model_info(f\"models:/{MODEL_NAME}/{latest_model_version}\")\n",
    "\n",
    "# Print the latest model version and its signature\n",
    "print(f\"Latest Model Version: {latest_model_version}\")\n",
    "print(f\"Model Signature: {model_info.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e98375-fb48-4065-a662-40b76096ed5f",
   "metadata": {},
   "source": [
    "# Loading the Model and Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e35f73-8f63-49fe-b2ce-d898a7cca69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained BERT similarity model from MLflow\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/{latest_model_version}\")\n",
    "\n",
    "# Define a sample query for testing\n",
    "query = \"Give me a resort budget vacation suggestion\"\n",
    "\n",
    "# Use the model to predict similar results based on the query\n",
    "result = model.predict({\"query\": [query]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec67eaa-b5ad-40f1-8ebe-6960450d9959",
   "metadata": {},
   "source": [
    "# Displaying Results for the Input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a8a05ef-585c-49a5-a539-8114342a6b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤═════════════════════════════════════════════════════════════════════════════════════════════════════╤═══════════════════╕\n",
      "│    │ Recommended Option                                                                                  │   Relevance Score │\n",
      "╞════╪═════════════════════════════════════════════════════════════════════════════════════════════════════╪═══════════════════╡\n",
      "│  0 │ For a budget-friendly vacation, consider a resort with vacation options and cruise activities.      │          0.869167 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  1 │ For a budget-friendly vacation, consider a getaway with beach options and vacation activities.      │          0.863822 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  2 │ For a budget-friendly vacation, consider a getaway with hotel options and vacation activities.      │          0.862292 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  3 │ For a budget-friendly vacation, consider a reservation with beach options and mountains activities. │          0.861587 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  4 │ For a budget-friendly wildlife, consider a vacation with vacation options and holiday activities.   │          0.861586 │\n",
      "╘════╧═════════════════════════════════════════════════════════════════════════════════════════════════════╧═══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Convert the result into a pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Drop unnecessary columns if needed\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"Topic\"], errors=\"ignore\")\n",
    "\n",
    "# Rename columns for better readability\n",
    "df.rename(columns={\"Pledge\": \"Recommended Option\", \"Similarity\": \"Relevance Score\"}, inplace=True)\n",
    "\n",
    "# Display the DataFrame in a tabular format\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3f8bf28-2065-4334-b73a-854a6e32a883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 02:31:18 - INFO - Notebook execution completed.\n"
     ]
    }
   ],
   "source": [
    "logger.info('Notebook execution completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5e133-ce6c-4c59-b61f-f707bb00c695",
   "metadata": {},
   "source": [
    "Built with ❤️ using Z by HP AI Studio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aistudio",
   "language": "python",
   "name": "aistudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
